# Copyright (c) 2017-present, Facebook, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
##############################################################################

"""Detection output visualization module."""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

import cv2
import numpy as np
import os
import colorsys
import random
from scipy.optimize import linear_sum_assignment

import pycocotools.mask as mask_util

from detectron.utils.colormap import colormap
import detectron.utils.env as envu
import detectron.utils.keypoints as keypoint_utils

# Matplotlib requires certain adjustments in some environments
# Must happen before importing matplotlib
envu.set_up_matplotlib()
import matplotlib.pyplot as plt
from matplotlib.patches import Polygon

plt.rcParams['pdf.fonttype'] = 42  # For editing in Adobe Illustrator


_GRAY = (218, 227, 218)
_GREEN = (18, 127, 15)
_WHITE = (255, 255, 255)


def kp_connections(keypoints):
    kp_lines = [
        [keypoints.index('left_eye'), keypoints.index('right_eye')],
        [keypoints.index('left_eye'), keypoints.index('nose')],
        [keypoints.index('right_eye'), keypoints.index('nose')],
        [keypoints.index('right_eye'), keypoints.index('right_ear')],
        [keypoints.index('left_eye'), keypoints.index('left_ear')],
        [keypoints.index('right_shoulder'), keypoints.index('right_elbow')],
        [keypoints.index('right_elbow'), keypoints.index('right_wrist')],
        [keypoints.index('left_shoulder'), keypoints.index('left_elbow')],
        [keypoints.index('left_elbow'), keypoints.index('left_wrist')],
        [keypoints.index('right_hip'), keypoints.index('right_knee')],
        [keypoints.index('right_knee'), keypoints.index('right_ankle')],
        [keypoints.index('left_hip'), keypoints.index('left_knee')],
        [keypoints.index('left_knee'), keypoints.index('left_ankle')],
        [keypoints.index('right_shoulder'), keypoints.index('left_shoulder')],
        [keypoints.index('right_hip'), keypoints.index('left_hip')],
    ]
    return kp_lines


def convert_from_cls_format(cls_boxes, cls_segms, cls_keyps):
    """Convert from the class boxes/segms/keyps format generated by the testing
    code.
    """
    box_list = [b for b in cls_boxes if len(b) > 0]
    if len(box_list) > 0:
        boxes = np.concatenate(box_list)
    else:
        boxes = None
    if cls_segms is not None:
        segms = [s for slist in cls_segms for s in slist]
    else:
        segms = None
    if cls_keyps is not None:
        keyps = [k for klist in cls_keyps for k in klist]
    else:
        keyps = None
    classes = []
    for j in range(len(cls_boxes)):
        classes += [j] * len(cls_boxes[j])
    return boxes, segms, keyps, classes


def get_class_string(class_index, score, dataset):
    class_text = dataset.classes[class_index] if dataset is not None else \
        'id{:d}'.format(class_index)
    return class_text + ' {:0.2f}'.format(score).lstrip('0')


def vis_mask(img, mask, col, alpha=0.4, show_border=True, border_thick=1):
    """Visualizes a single binary mask."""

    img = img.astype(np.float32)
    idx = np.nonzero(mask)

    img[idx[0], idx[1], :] *= 1.0 - alpha
    img[idx[0], idx[1], :] += alpha * col

    if show_border:
        _, contours, _ = cv2.findContours(
            mask.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)
        cv2.drawContours(img, contours, -1, _WHITE, border_thick, cv2.LINE_AA)

    return img.astype(np.uint8)


def vis_class(img, pos, class_str, font_scale=0.35):
    """Visualizes the class."""
    img = img.astype(np.uint8)
    x0, y0 = int(pos[0]), int(pos[1])
    # Compute text size.
    txt = class_str
    font = cv2.FONT_HERSHEY_SIMPLEX
    ((txt_w, txt_h), _) = cv2.getTextSize(txt, font, font_scale, 1)
    # Place text background.
    back_tl = x0, y0 - int(1.3 * txt_h)
    back_br = x0 + txt_w, y0
    cv2.rectangle(img, back_tl, back_br, _GREEN, -1)
    # Show text.
    txt_tl = x0, y0 - int(0.3 * txt_h)
    cv2.putText(img, txt, txt_tl, font, font_scale, _GRAY, lineType=cv2.LINE_AA)
    return img


def vis_bbox(img, bbox, thick=2, color=_GREEN):
    """Visualizes a bounding box."""
    img = img.astype(np.uint8)
    (x0, y0, w, h) = bbox
    x1, y1 = int(x0 + w), int(y0 + h)
    x0, y0 = int(x0), int(y0)
    cv2.rectangle(img, (x0, y0), (x1, y1), color, thickness=thick)
    return img


def vis_keypoints(img, kps, kp_thresh=2, alpha=0.7):
    """Visualizes keypoints (adapted from vis_one_image).
    kps has shape (4, #keypoints) where 4 rows are (x, y, logit, prob).
    """
    dataset_keypoints, _ = keypoint_utils.get_keypoints()
    kp_lines = kp_connections(dataset_keypoints)

    # Convert from plt 0-1 RGBA colors to 0-255 BGR colors for opencv.
    cmap = plt.get_cmap('rainbow')
    colors = [cmap(i) for i in np.linspace(0, 1, len(kp_lines) + 2)]
    colors = [(c[2] * 255, c[1] * 255, c[0] * 255) for c in colors]

    # Perform the drawing on a copy of the image, to allow for blending.
    kp_mask = np.copy(img)

    # Draw mid shoulder / mid hip first for better visualization.
    mid_shoulder = (
        kps[:2, dataset_keypoints.index('right_shoulder')] +
        kps[:2, dataset_keypoints.index('left_shoulder')]) / 2.0
    sc_mid_shoulder = np.minimum(
        kps[2, dataset_keypoints.index('right_shoulder')],
        kps[2, dataset_keypoints.index('left_shoulder')])
    mid_hip = (
        kps[:2, dataset_keypoints.index('right_hip')] +
        kps[:2, dataset_keypoints.index('left_hip')]) / 2.0
    sc_mid_hip = np.minimum(
        kps[2, dataset_keypoints.index('right_hip')],
        kps[2, dataset_keypoints.index('left_hip')])
    nose_idx = dataset_keypoints.index('nose')
    if sc_mid_shoulder > kp_thresh and kps[2, nose_idx] > kp_thresh:
        cv2.line(
            kp_mask, tuple(mid_shoulder), tuple(kps[:2, nose_idx]),
            color=colors[len(kp_lines)], thickness=2, lineType=cv2.LINE_AA)
    if sc_mid_shoulder > kp_thresh and sc_mid_hip > kp_thresh:
        cv2.line(
            kp_mask, tuple(mid_shoulder), tuple(mid_hip),
            color=colors[len(kp_lines) + 1], thickness=2, lineType=cv2.LINE_AA)

    # Draw the keypoints.
    for l in range(len(kp_lines)):
        i1 = kp_lines[l][0]
        i2 = kp_lines[l][1]
        p1 = kps[0, i1], kps[1, i1]
        p2 = kps[0, i2], kps[1, i2]
        if kps[2, i1] > kp_thresh and kps[2, i2] > kp_thresh:
            cv2.line(
                kp_mask, p1, p2,
                color=colors[l], thickness=2, lineType=cv2.LINE_AA)
        if kps[2, i1] > kp_thresh:
            cv2.circle(
                kp_mask, p1,
                radius=3, color=colors[l], thickness=-1, lineType=cv2.LINE_AA)
        if kps[2, i2] > kp_thresh:
            cv2.circle(
                kp_mask, p2,
                radius=3, color=colors[l], thickness=-1, lineType=cv2.LINE_AA)

    # Blend the keypoints.
    return cv2.addWeighted(img, 1.0 - alpha, kp_mask, alpha, 0)

def distinct_colors(n):
    hsv_tuples = [(x*1.0/n, 0.5, 0.5) for x in range(n)]
    rgb_tuples = map(lambda x: [c  * 255 for c in colorsys.hsv_to_rgb(*x)], hsv_tuples)
    return rgb_tuples

def vis_image_pair_opencv(
        im_list, boxes_list, segms_list=None, keypoints_list=None, track=None, thresh=0.9, kp_thresh=2, track_thresh=0.7,
        show_box=False, dataset=None, show_class=False, show_track=False, show_track_ids=False, colors=None, color_inds_list=None):
    """Constructs a numpy array with the detections visualized."""

    classes_list = []
    keep_idx = [[], []]
    sorted_inds_list = []
    ret = []
    color_inds_list_new = [None, None]
    masks_list = []

    for i, im in enumerate(im_list):
        boxes = boxes_list[i]
        segms = None if segms_list is None else segms_list[i]
        keypoints = None if keypoints_list is None else keypoints_list[i]

        if isinstance(boxes, list):
            boxes, segms, keypoints, classes = convert_from_cls_format(
                boxes, segms, keypoints)
            boxes_list[i] = boxes
            segms_list[i] = segms
            keypoints_list[i] = keypoints
            classes_list.append(classes)

        if boxes is None or boxes.shape[0] == 0 or max(boxes[:, 4]) < thresh:
            if im is not None:
                ret.append(im)
            continue

        if segms is not None and len(segms) > 0:
            masks_list.append(mask_util.decode(segms))

        # Display in largest to smallest order to reduce occlusion
        areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
        sorted_inds = np.argsort(-areas)
        sorted_inds_list.append(sorted_inds)

        for idx in sorted_inds:
            bbox = boxes[idx, :4]
            score = boxes[idx, -1]
            if score >= thresh:
                keep_idx[i].append(idx)

    n_rois = len(boxes_list[0])
    m_rois = len(boxes_list[1])

    assert(len(sorted_inds_list[0]) == n_rois)
    assert(len(sorted_inds_list[1]) == m_rois)
    assert(track.shape == (n_rois, m_rois))

    if color_inds_list is None:
        color_inds_list = [None, None]
    for i in xrange(2):
        if color_inds_list[i] is not None:
            assert(len(color_inds_list[i]) == len(boxes_list[i]))
        else:
            color_inds_list[i] = [None] * len(boxes_list[i])
        color_inds_list_new[i] = [None] * len(boxes_list[i])

    assign_inds_one = []

    track_prob_mat = np.zeros((n_rois, m_rois))
    for i in keep_idx[0]:
        for j in keep_idx[1]:
            track_prob_mat[i, j] = track[m_rois * i + j]
    track_prob_mat = np.where(track_prob_mat > track_thresh, track_prob_mat, np.zeros((n_rois, m_rois)))
    track_prob_mat = np.where(np.array([[class_one == class_two for class_two in classes_list[1]] for class_one in classes_list[0]]), track_prob_mat, np.zeros((n_rois, m_rois)))
    assign_inds_list = linear_sum_assignment(-track_prob_mat)

    if colors is None:
        colors = distinct_colors(min(len(keep_idx[0]), len(keep_idx[1])))
    
    for i, im in enumerate(im_list):
        boxes = boxes_list[i]
        classes = classes_list[i]
        assign_inds = assign_inds_list[i]
        if i == 1:
            color_inds_list[0] = color_inds_list_new[0]
        for idx in keep_idx[i]:
            bbox = boxes[idx, :4]
            score = boxes[idx, -1]
            if idx not in assign_inds:
                continue
            i_other = (0 if i == 1 else 1)
            assign_inds_other = assign_inds_list[i_other]
            i_assign = assign_inds.tolist().index(idx)
            idx_other = assign_inds_other[i_assign]
            if idx_other not in keep_idx[i_other]:
                continue
  
            if i == 0:
                assign_inds_one.append(i_assign)

            i_color = color_inds_list[i][idx]
            if i_color is None:
                if color_inds_list[i_other][idx_other] is None:
                    color_inds = np.unique([x for x in color_inds_list[i_other] + color_inds_list[i] if x is not None])
                    if len(color_inds):
                        i_small_idx = np.where(np.not_equal(color_inds, np.array(range(len(color_inds)))))[0]
                        if len(i_small_idx):
                            i_color = i_small_idx[0]
                        else:
                            i_color = max(color_inds) + 1
                    else:
                        i_color = assign_inds_one.index(i_assign)
                    assert(i_color not in color_inds)
                else:
                    i_color = color_inds_list[i_other][idx_other]
            assert(i_color is not None)

            color_inds_list_new[i][idx] = i_color

            if im is not None:
                if i == 0:
                    track_prob = track_prob_mat[idx, idx_other]
                else:
                    track_prob = track_prob_mat[idx_other, idx]
                # show box (off by default)
                if track_prob < track_thresh:
                    color = (127.5, 127.5, 127.5)
                    thick = 1
                else:
                    color = colors[i_color]
                    thick = 2
                if show_box:
                    im = vis_bbox(
                        im, (bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]), color=color, thick=thick)

                # show class (off by default)
                class_str = ""
                if show_class:
                    class_str = get_class_string(classes[idx], score, dataset)
                    if show_track:
                        class_str += " | "
                if show_track:
                    class_str += "{:.2f}".format(track_prob)
                    if show_track_ids:
                        class_str += ", {} --> {}".format(idx, idx_other)
                if show_class or show_track:
                    im = vis_class(im, (bbox[0], bbox[1] - 2), class_str)

                # show mask
                if segms is not None and len(segms) > idx:
                    color_mask = np.array(colors[i_color])
                    im = vis_mask(im, masks_list[i][..., idx], color_mask)

                # show keypoints
                if keypoints is not None and len(keypoints) > idx:
                    im = vis_keypoints(im, keypoints_list[i][idx], 2)

        if im is not None:
            im = vis_class(im, (10, 20), str(i))
            ret.append(im)
    
    ret.append(track_prob_mat)
    ret += color_inds_list_new

    return ret

def vis_image_pair_opencv_gt(
        im_list, classes_list, boxes_list, masks_list=None, keypoints_list=None, track=None,
        show_box=False, dataset=None, show_class=False, show_track=False):
    """Constructs a numpy array with the detections visualized."""

    sorted_inds_list = []
    ret = []

    for i, im in enumerate(im_list):
        boxes = boxes_list[i]
        masks = None if masks_list is None else masks_list[0]
        keypoints = None if keypoints_list is None else keypoints_list[0]

        if boxes is None or boxes.shape[0] == 0:
            return im

        if masks is not None and len(masks) > 0:
            color_list = colormap()
            mask_color_id = 0

        # Display in largest to smallest order to reduce occlusion
        areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
        sorted_inds = np.argsort(-areas)
        sorted_inds_list.append(sorted_inds)

        for idx in sorted_inds:
            bbox = boxes[idx, :4]

    n_rois = len(boxes_list[0])
    m_rois = len(boxes_list[1])

    assert(len(sorted_inds_list[0]) == n_rois)
    assert(len(sorted_inds_list[1]) == m_rois)
    assert(len(track) == n_rois * m_rois)

    track_prob_mat = np.zeros((n_rois, m_rois))

    for i in sorted_inds_list[0]:
        for j in sorted_inds_list[1]:
            track_prob_mat[i, j] = track[m_rois * i + j]
    assign_inds_list = linear_sum_assignment(-track_prob_mat)

    colors = distinct_colors(min(n_rois, m_rois))

    for i, im in enumerate(im_list):
        boxes = boxes_list[i]
        classes = classes_list[i]
        sorted_inds = sorted_inds_list[i]
        assign_inds = assign_inds_list[i]
        for idx in sorted_inds:
            bbox = boxes[idx, :4]
            score = boxes[idx, -1]
            if idx not in assign_inds:
                continue
            i_other = (0 if i == 1 else 1)
            assign_inds_other = assign_inds_list[i_other]
            i_track = assign_inds.tolist().index(idx)
            idx_other = assign_inds_other[i_track]
            if idx_other not in sorted_inds_list[i_other]:
                continue
            if i == 0:
                track_prob = track_prob_mat[idx, idx_other]
            else:
                track_prob = track_prob_mat[idx_other, idx]
            if track_prob == 0.:
                continue

            # show box (off by default)
            if show_box:
                im = vis_bbox(
                    im, (bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]), color=colors[i_track])

            # show class (off by default)
            class_str = ""
            if show_class:
                class_str += dataset.classes[classes[idx]] if dataset is not None else \
                'id{:d}'.format(classes[idx])
                if show_track:
                    class_str += " | "
            if show_track:
                class_str += "{} --> {}".format(idx, idx_other)
            if show_class or show_track:
                im = vis_class(im, (bbox[0], bbox[1] - 2), class_str)

            # show mask
            if masks is not None and len(masks) > idx:
                color_mask = color_list[mask_color_id % len(color_list), 0:3]
                mask_color_id += 1
                im = vis_mask(im, masks[..., idx], color_mask)

            # show keypoints
            if keypoints is not None and len(keypoints) > i:
                im = vis_keypoints(im, keypoints[i], 0)

        ret.append(im)

    return ret

def vis_one_image_opencv(
        im, boxes, segms=None, keypoints=None, thresh=0.9, kp_thresh=2,
        show_box=False, dataset=None, show_class=False):
    """Constructs a numpy array with the detections visualized."""

    if isinstance(boxes, list):
        boxes, segms, keypoints, classes = convert_from_cls_format(
            boxes, segms, keypoints)

    if boxes is None or boxes.shape[0] == 0 or max(boxes[:, 4]) < thresh:
        return im

    if segms is not None and len(segms) > 0:
        masks = mask_util.decode(segms)
        color_list = colormap()
        mask_color_id = 0

    # Display in largest to smallest order to reduce occlusion
    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    sorted_inds = np.argsort(-areas)

    for i in sorted_inds:
        bbox = boxes[i, :4]
        score = boxes[i, -1]
        if score < thresh:
            continue

        # show box (off by default)
        if show_box:
            im = vis_bbox(
                im, (bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]))

        # show class (off by default)
        if show_class or show_track:
            im = vis_class(im, (bbox[0], bbox[1] - 2), class_str)

        # show mask
        if segms is not None and len(segms) > i:
            color_mask = color_list[mask_color_id % len(color_list), 0:3]
            mask_color_id += 1
            im = vis_mask(im, masks[..., i], color_mask)

        # show keypoints
        if keypoints is not None and len(keypoints) > i:
            im = vis_keypoints(im, keypoints[i], 2)

    return im

obj_id_to_i_color = {}

def vis_detections_one_image_opencv(
        im, detections, detections_prev=[], thresh=0.9, kp_thresh=2, track_thresh=0.8,
        show_box=False, dataset=None, show_class=False, show_track=False, n_colors=None):
    """Constructs a numpy array with the detections visualized."""
    global obj_id_to_i_color

    classes =  [det.cls for det in detections]
    segms =  [det.segm for det in detections]
    boxes = np.array([det.box for det in detections])
    keypoints = [det.kps for det in detections]
    if all(v is None for v in segms):
        segms = None
    if all(v is None for v in keypoints):
        keypoints = None

    if boxes is None or boxes.shape[0] == 0 or max(boxes[:, 4]) < thresh:
        return im

    color_by_obj_id = True
    obj_ids = np.unique([det.obj_id for det in detections_prev] + [det.obj_id for det in detections]).tolist()
    if n_colors is None:
        if detections is None:
            colors = distinct_colors(len(boxes))
            obj_id_to_i_color = {i: i for i in xrange(len(boxes))}
        else:
            color_by_obj_id = False
            colors = distinct_colors(len(obj_ids))
    else:
        colors = distinct_colors(n_colors)
    if segms is not None and len(segms) > 0:
        masks = mask_util.decode(segms)

    # Display in largest to smallest order to reduce occlusion
    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    sorted_inds = np.argsort(-areas)

    for i in sorted_inds:
        bbox = boxes[i, :4]
        score = boxes[i, -1]
        if score < thresh:
            continue

        if detections is None:
            i_color = i
        else:
            detection = detections[i]
            if color_by_obj_id:
                i_color = obj_id_to_i_color.get(detection.obj_id)
                if i_color is None:
                    i_color = random.randint(0, n_colors - 1)
                    obj_id_to_i_color[detection.obj_id] = i_color
            else:
                i_color = obj_ids.index(detection.obj_id)

        # show box (off by default)
        if show_box:
            if detections is None:
                im = vis_bbox(
                    im, (bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]))
            else:
                detection = detections[i]
                if detection.conf_prev < track_thresh or detection.cls != 1:
                    color = (127.5, 127.5, 127.5)
                    thick = 1
                else:
                    color = colors[i_color]
                    thick = 2
                im = vis_bbox(
                    im, (bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]), color=color, thick=thick)

        # show class (off by default)
        det_str = ""
        if show_class:
            det_str += dataset.classes[classes[i]] if dataset is not None else \
            'id {:d}'.format(classes[i])
            det_str += ' {:0.2f}'.format(score).lstrip('0')
            if show_track:
                det_str += " | "
        if show_track:
            det_str += "[{}]".format(detection.obj_id)
            det_str += ' {:0.2f}'.format(detection.conf_prev).lstrip('0')
        if show_class or show_track:
                im = vis_class(im, (bbox[0], bbox[1] - 2), det_str)
        

        # show mask
        if segms is not None and len(segms) > i:
            color_mask = np.array(color)
            im = vis_mask(im, masks[..., i], color_mask)

        # show keypoints
        if keypoints is not None and len(keypoints) > i:
            im = vis_keypoints(im, np.array(keypoints[i]), 2)

    return im

def vis_tracking_one_image_opencv(
    im, detections, thresh=0.9, dataset=None, show_class=False, colors=None):

    for i, detection in enumerate(detections):
        if len(detection) == 10:
            _, obj_id, bb_left, bb_top, bb_width, bb_height, conf, _, _, _ = detection
        else:
            _, obj_id, bb_left, bb_top, bb_width, bb_height, conf, cls, _ = detection
        bbox = [bb_left, bb_top, bb_width, bb_height]
        if conf != -1 and conf < thresh:
            continue

        color = colors[obj_id]

        im = vis_bbox(
            im, (bbox[0], bbox[1], bbox[2], bbox[3]), color=color)

        det_str = ""
        # show class (off by default)
        if show_class:
            det_str += dataset.classes[cls] if dataset is not None else \
            'id {:d}'.format(cls)
            det_str += " | "
        det_str += "[{}]".format(obj_id)
        det_str += ' {:0.2f}'.format(conf).lstrip('0')
        im = vis_class(im, (bbox[0], bbox[1] - 2), det_str)
        
    return im

def vis_one_image_opencv_gt(
        im, classes, boxes, masks=None, keypoints=None,
        show_box=False, dataset=None, show_class=False):
    """Constructs a numpy array with the detections visualized."""

    if boxes is None or boxes.shape[0] == 0:
        return im

    if masks is not None and len(masks) > 0:
        color_list = colormap()
        mask_color_id = 0

    # Display in largest to smallest order to reduce occlusion
    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    sorted_inds = np.argsort(-areas)

    for i in sorted_inds:
        bbox = boxes[i, :4]

        # show box (off by default)
        if show_box:
            im = vis_bbox(
                im, (bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]))

        # show class (off by default)
        if show_class:
            class_str = dataset.classes[classes[i]] if dataset is not None else \
                'id{:d}'.format(classes[i])
            im = vis_class(im, (bbox[0], bbox[1] - 2), class_str)
        # show mask
        if masks is not None and len(masks) > i:
            color_mask = color_list[mask_color_id % len(color_list), 0:3]
            mask_color_id += 1
            im = vis_mask(im, masks[..., i], color_mask)

        # show keypoints
        if keypoints is not None and len(keypoints) > i:
            im = vis_keypoints(im, keypoints[i], 0)

    return im


def vis_one_image(
        im, im_name, output_dir, boxes, segms=None, keypoints=None, thresh=0.9,
        kp_thresh=2, dpi=200, box_alpha=0.0, dataset=None, show_class=False,
        ext='pdf', out_when_no_box=False):
    """Visual debugging of detections."""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    if isinstance(boxes, list):
        boxes, segms, keypoints, classes = convert_from_cls_format(
            boxes, segms, keypoints)

    if (boxes is None or boxes.shape[0] == 0 or max(boxes[:, 4]) < thresh) and not out_when_no_box:
        return

    dataset_keypoints, _ = keypoint_utils.get_keypoints()

    if segms is not None and len(segms) > 0:
        masks = mask_util.decode(segms)

    color_list = colormap(rgb=True) / 255

    kp_lines = kp_connections(dataset_keypoints)
    cmap = plt.get_cmap('rainbow')
    colors = [cmap(i) for i in np.linspace(0, 1, len(kp_lines) + 2)]

    fig = plt.figure(frameon=False)
    fig.set_size_inches(im.shape[1] / dpi, im.shape[0] / dpi)
    ax = plt.Axes(fig, [0., 0., 1., 1.])
    ax.axis('off')
    fig.add_axes(ax)
    ax.imshow(im)

    if boxes is None:
        sorted_inds = [] # avoid crash when 'boxes' is None
    else:
        # Display in largest to smallest order to reduce occlusion
        areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
        sorted_inds = np.argsort(-areas)

    mask_color_id = 0
    for i in sorted_inds:
        bbox = boxes[i, :4]
        score = boxes[i, -1]
        if score < thresh:
            continue

        # show box (off by default)
        ax.add_patch(
            plt.Rectangle((bbox[0], bbox[1]),
                          bbox[2] - bbox[0],
                          bbox[3] - bbox[1],
                          fill=False, edgecolor='g',
                          linewidth=0.5, alpha=box_alpha))

        if show_class:
            ax.text(
                bbox[0], bbox[1] - 2,
                get_class_string(classes[i], score, dataset),
                fontsize=3,
                family='serif',
                bbox=dict(
                    facecolor='g', alpha=0.4, pad=0, edgecolor='none'),
                color='white')

        # show mask
        if segms is not None and len(segms) > i:
            img = np.ones(im.shape)
            color_mask = color_list[mask_color_id % len(color_list), 0:3]
            mask_color_id += 1

            w_ratio = .4
            for c in range(3):
                color_mask[c] = color_mask[c] * (1 - w_ratio) + w_ratio
            for c in range(3):
                img[:, :, c] = color_mask[c]
            e = masks[:, :, i]

            _, contour, hier = cv2.findContours(
                e.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)

            for c in contour:
                polygon = Polygon(
                    c.reshape((-1, 2)),
                    fill=True, facecolor=color_mask,
                    edgecolor='w', linewidth=1.2,
                    alpha=0.5)
                ax.add_patch(polygon)

        # show keypoints
        if keypoints is not None and len(keypoints) > i and dataset.classes[classes[i]] == 'person':
            kps = keypoints[i]
            plt.autoscale(False)
            for l in range(len(kp_lines)):
                i1 = kp_lines[l][0]
                i2 = kp_lines[l][1]
                if kps[2, i1] > kp_thresh and kps[2, i2] > kp_thresh:
                    x = [kps[0, i1], kps[0, i2]]
                    y = [kps[1, i1], kps[1, i2]]
                    line = plt.plot(x, y)
                    plt.setp(line, color=colors[l], linewidth=1.0, alpha=0.7)
                if kps[2, i1] > kp_thresh:
                    plt.plot(
                        kps[0, i1], kps[1, i1], '.', color=colors[l],
                        markersize=3.0, alpha=0.7)

                if kps[2, i2] > kp_thresh:
                    plt.plot(
                        kps[0, i2], kps[1, i2], '.', color=colors[l],
                        markersize=3.0, alpha=0.7)

            # add mid shoulder / mid hip for better visualization
            mid_shoulder = (
                kps[:2, dataset_keypoints.index('right_shoulder')] +
                kps[:2, dataset_keypoints.index('left_shoulder')]) / 2.0
            sc_mid_shoulder = np.minimum(
                kps[2, dataset_keypoints.index('right_shoulder')],
                kps[2, dataset_keypoints.index('left_shoulder')])
            mid_hip = (
                kps[:2, dataset_keypoints.index('right_hip')] +
                kps[:2, dataset_keypoints.index('left_hip')]) / 2.0
            sc_mid_hip = np.minimum(
                kps[2, dataset_keypoints.index('right_hip')],
                kps[2, dataset_keypoints.index('left_hip')])
            if (sc_mid_shoulder > kp_thresh and
                    kps[2, dataset_keypoints.index('nose')] > kp_thresh):
                x = [mid_shoulder[0], kps[0, dataset_keypoints.index('nose')]]
                y = [mid_shoulder[1], kps[1, dataset_keypoints.index('nose')]]
                line = plt.plot(x, y)
                plt.setp(
                    line, color=colors[len(kp_lines)], linewidth=1.0, alpha=0.7)
            if sc_mid_shoulder > kp_thresh and sc_mid_hip > kp_thresh:
                x = [mid_shoulder[0], mid_hip[0]]
                y = [mid_shoulder[1], mid_hip[1]]
                line = plt.plot(x, y)
                plt.setp(
                    line, color=colors[len(kp_lines) + 1], linewidth=1.0,
                    alpha=0.7)

    output_name = os.path.basename(im_name) + '.' + ext
    fig.savefig(os.path.join(output_dir, '{}'.format(output_name)), dpi=dpi)
    plt.close('all')


def get_ax(n, figsize=(12, 12), shape=(), title=None):
    _, ax = plt.subplots(n, 1, figsize=figsize)
    for i in xrange(n):
        ax[i].axis('off')
        ax[i].set_ylim(shape[0], 0)
        ax[i].set_xlim(0, shape[1])
        ax[i].set_title(title, color='white')
    return ax
